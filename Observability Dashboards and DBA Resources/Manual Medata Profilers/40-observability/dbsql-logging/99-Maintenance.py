# Databricks notebook source
# MAGIC %run ./00-Config

# COMMAND ----------

# DBTITLE 1,Optimize & zOrder
spark.sql(f'OPTIMIZE {DATABASE_NAME}.{QUERIES_TABLE_NAME} ZORDER BY {QUERIES_ZORDER}')
spark.sql(f'OPTIMIZE {DATABASE_NAME}.{WAREHOUSES_TABLE_NAME} ZORDER BY {WAREHOUSES_ZORDER}')
spark.sql(f'OPTIMIZE {DATABASE_NAME}.{DASHBOARDS_TABLE_NAME} ZORDER BY {DASHBOARDS_ZORDER}')
spark.sql(f'OPTIMIZE {DATABASE_NAME}.{WORKFLOWS_TABLE_NAME} ZORDER BY {WORKFLOWS_ZORDER}')

# COMMAND ----------

# DBTITLE 1,Allow for parallel deletes in Vacuum
spark.conf.set("spark.databricks.delta.vacuum.parallelDelete.enabled", True)

# COMMAND ----------

# DBTITLE 1,Delete small files no longer in use
spark.sql(f'VACUUM {DATABASE_NAME}.{QUERIES_TABLE_NAME} RETAIN {VACUUM_RETENTION} HOURS')
spark.sql(f'VACUUM {DATABASE_NAME}.{WAREHOUSES_TABLE_NAME} RETAIN {VACUUM_RETENTION} HOURS')
spark.sql(f'VACUUM {DATABASE_NAME}.{DASHBOARDS_TABLE_NAME} RETAIN {VACUUM_RETENTION} HOURS')
spark.sql(f'VACUUM {DATABASE_NAME}.{WORKFLOWS_TABLE_NAME} RETAIN {VACUUM_RETENTION} HOURS')
